{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Retro\\anaconda3\\envs\\boruta_test1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019907 -0.017646  \n",
       "1 -0.039493 -0.068332 -0.092204  \n",
       "2 -0.002592  0.002861 -0.025930  \n",
       "3  0.034309  0.022688 -0.009362  \n",
       "4 -0.002592 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from BorutaShap import BorutaShap, load_data\n",
    "\n",
    "    \n",
    "X, y = load_data(data_type='regression')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████████▊                                                                                                                                                               | 8/100 [01:00<09:56,  6.48s/it]"
     ]
    }
   ],
   "source": [
    "# no model selected default is Random Forest, if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(importance_measure='shap',\n",
    "                              classification=False)\n",
    "\n",
    "Feature_Selector.fit(X=X, y=y, n_trials=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Boxplot of features\n",
    "# I would recommend plotting Y axis on the Log Scale\n",
    "Feature_Selector.plot(X_size=12, figsize=(12,8),\n",
    "            y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = Feature_Selector.Subset()\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no model selected default is Random Forest, if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(importance_measure='gini',\n",
    "                              classification=False)\n",
    "\n",
    "Feature_Selector.fit(X=X, y=y, n_trials=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Boxplot of features\n",
    "# I would recommend plotting Y axis on the Log Scale\n",
    "Feature_Selector.plot(X_size=12, figsize=(12,8),\n",
    "            y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Regression Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no model selected default is Random Forest, if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(importance_measure='shap',\n",
    "                              classification=False)\n",
    "\n",
    "Feature_Selector.fit(X=X, y=y, n_trials=100, random_state=0, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Boxplot of features\n",
    "# I would recommend plotting Y axis on the Log Scale\n",
    "Feature_Selector.plot(X_size=12, figsize=(12,8),\n",
    "            y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = np.array(y)\n",
    "y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=2, test_size = int(np.floor(X.shape[0]*0.1)))\n",
    "train_index, test_index = list(tscv.split(X))[1]\n",
    "X.iloc[train_index], X.iloc[test_index], y[train_index], y[test_index], y_np[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTimeSeriesSplit1:\n",
    "    \"\"\"\n",
    "    A custom time series splitter that generates train-test splits for time series data.\n",
    "    \n",
    "    Attributes:\n",
    "    ----------\n",
    "    n_splits : int\n",
    "        The number of splits to generate.\n",
    "    test_size : float\n",
    "        The fraction of data to be used as the test set in each split.\n",
    "    step_size : float\n",
    "        The fraction of data to be used as the step size for shifting the window.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    split(X, y=None, groups=None):\n",
    "        Generates train-test indices for each split.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=3, test_size=0.2, step_size=0.05):\n",
    "        \"\"\"\n",
    "        Initializes the CustomTimeSeriesSplit with the given parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        n_splits : int, optional\n",
    "            The number of splits to generate (default is 3).\n",
    "        test_size : float, optional\n",
    "            The fraction of data to be used as the test set in each split (default is 0.2).\n",
    "        step_size : float, optional\n",
    "            The fraction of data to be used as the step size for shifting the window (default is 0.05).\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"\n",
    "        Generates train-test indices for each split.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data to split.\n",
    "        y : array-like, shape (n_samples,), optional\n",
    "            The target variable (not used in this method).\n",
    "        groups : array-like, shape (n_samples,), optional\n",
    "            Group labels for the samples (not used in this method).\n",
    "\n",
    "        Yields:\n",
    "        -------\n",
    "        train_idx : ndarray\n",
    "            Indices for the training data.\n",
    "        test_idx : ndarray\n",
    "            Indices for the test data.\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        \n",
    "        # Calculate test size and step size in terms of number of samples\n",
    "        n_test = builtins.max(int(n_samples * self.test_size), 1)\n",
    "        step = builtins.max(int(n_samples * self.step_size), 1)\n",
    "        \n",
    "        # Adjust the number of splits if necessary\n",
    "        max_splits = (n_samples - n_test) // step + 1\n",
    "        n_splits = builtins.min(self.n_splits, max_splits)\n",
    "        \n",
    "        test_starts = range(n_samples - n_test, n_samples - n_test - n_splits * step, -step)\n",
    "        \n",
    "        indices = np.arange(n_samples)\n",
    "        for test_start in test_starts:\n",
    "            test_end = test_start + n_test\n",
    "            train_idx = indices[:test_start]\n",
    "            test_idx = indices[test_start:test_end]\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "\n",
    "def custom_tscv_split(df,grouping_col, n_splits=3, test_size=0.2, step_size=0.05):\n",
    "    \"\"\"\n",
    "    Splits time series data into train-test sets based on a custom time series cross-validation scheme.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be split.\n",
    "    grouping_col : str\n",
    "        The column name to group the data by (e.g., series ID).\n",
    "    n_splits : int, optional\n",
    "        The number of splits to generate (default is 3).\n",
    "    test_size : float, optional\n",
    "        The fraction of data to be used as the test set in each split (default is 0.2).\n",
    "    step_size : float, optional\n",
    "        The fraction of data to be used as the step size for shifting the window (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list of tuples\n",
    "        Each tuple contains two DataFrames: the training set and the test set for a split.\n",
    "    \"\"\"\n",
    "    tscv = CustomTimeSeriesSplit1(n_splits=n_splits, test_size=test_size, step_size=step_size)\n",
    "    grouped = df.groupby(grouping_col)\n",
    "\n",
    "    train_splits = [[] for _ in range(n_splits)]\n",
    "    test_splits = [[] for _ in range(n_splits)]\n",
    "    \n",
    "    for series_id, group in grouped:\n",
    "        group = group.reset_index(drop=True)\n",
    "        n_samples = len(group)\n",
    "        \n",
    "        n_test = builtins.max(int(n_samples * test_size), 1)\n",
    "        step = builtins.max(int(n_samples * step_size), 1)\n",
    "        max_splits = (n_samples - n_test) // step + 1\n",
    "        actual_splits = builtins.min(n_splits, max_splits)\n",
    "        \n",
    "        #if actual_splits < 1:\n",
    "        if n_samples < 60:\n",
    "            print(f\"Series {series_id} does not have enough data for the specified number of splits. Defaulting to single train-test split.\")\n",
    "            train_idx = np.arange(n_samples - n_test)\n",
    "            test_idx = np.arange(n_samples - n_test, n_samples)\n",
    "            for i in range(n_splits):\n",
    "                train_splits[i].append(group.iloc[train_idx])\n",
    "                test_splits[i].append(group.iloc[test_idx])\n",
    "        else:\n",
    "            split_count = 0\n",
    "            for train_idx, test_idx in tscv.split(group):\n",
    "                if split_count < n_splits:\n",
    "                    train_splits[split_count].append(group.iloc[train_idx])\n",
    "                    test_splits[split_count].append(group.iloc[test_idx])\n",
    "                    split_count += 1\n",
    "    \n",
    "    # Concatenate valid splits\n",
    "    train_splits = [pd.concat(split) if split else pd.DataFrame() for split in train_splits]\n",
    "    test_splits = [pd.concat(split) if split else pd.DataFrame() for split in test_splits]\n",
    "    \n",
    "    return list(zip(train_splits, test_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['grp'] = 'all'\n",
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "import pandas as pd\n",
    "splits = custom_tscv_split(X, grouping_col = 'grp', n_splits=2,\\\n",
    "                            test_size = 0.1,step_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index.shape[0]}\")\n",
    "    print(f\"  Test:  index={test_index.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
